---
title: "DATA 605 HW 3"
author: "Kevin Havis"
date: "April 10, 2025"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(tidyverse)
library(glue)
library(pracma)
```


# Problem 1: Transportation Safety

## Scenario
You are a data analyst at a transportation safety organization. Your task is to analyze the relationship between the speed of cars and their stopping distance using the built-in R dataset `cars`. This analysis will help in understanding how speed affects the stopping distance, which is crucial for improving road safety regulations.

## Tasks

### Data Visualization
```{r cars_visualization}

data(cars)

# Create a scatter plot of stopping distance (dist) as a function of speed (speed)

plot <- cars |> 
  ggplot(aes(speed, dist)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) + # Add a regression line to the plot
  ggtitle("Stopping Distance vs Speed")
print(plot)

```

### Build a Linear Model
```{r cars_linear_model}
# Construct a simple linear regression model
model <- lm(dist ~ speed, data=cars)

# Summarize the model
summary(model)
```

### Model Quality Evaluation
```{r model_quality}
# Calculate and interpret the R-squared value
summary(model)$r.squared
# Perform a residual analysis
plot(density(resid(model)))

```

### Residual Analysis
```{r residual_analysis}
# Plot residuals versus fitted values
plot(model, 1)
# Create Q-Q plot of residuals
plot(model, 2)
# Perform Shapiro-Wilk test

# Plot histogram of residuals
plot(hist(resid(model)))
```

### Conclusion
*Write your conclusion here discussing model appropriateness, assumptions, and potential improvements.*

Our model shows about 65% of the variance in stopping distance is explained by increases in speed, which is a very good indicator of a postiive linear relationship.

Additionally, when reviewing our residuals (both in the QQ plot and histogram), we can see that they are well distributed about zero. This is also a good indicator of a high performing linear model; we expect this type of random variance to have a mean of zero.

Regarding improvements, there are a few outliers near zero I can see that may be skewing the regression. To improve generalized performance, it may be worth removing those and running the model again.

# Problem 2: Health Policy Analysis

## Scenario
As a health policy analyst for an international organization, you are tasked with analyzing data from the World Health Organization (WHO) to inform global health policies. The dataset provided (who.csv) contains crucial health indicators for various countries from the year 2008.

## Question 1: Health Policy Analyst

```{r who_data_import}
# Import the WHO dataset
who <- read_csv("who.csv")

# Remove empty column
who <- who |> 
  select(!c("...10", "LifeExp...12")) |> 
  rename(LifeExp = LifeExp...2)
```

```{r q1_visualization}
# Create a scatterplot of LifeExp vs. TotExp

plot <- who |> 
  ggplot(aes(TotExp, LifeExp)) +
  geom_point()

print(plot)

```

```{r q1_linear_regression}
# Run a simple linear regression model
who_model <- lm(LifeExp ~ TotExp, data=who)
summary(who_model)
```

*Interpret F-statistic, R-squared value, standard error, and p-values here.*

- F-statistic: The F-statistic measure the ratio of variance, which we expect to close to 1 if there is no relationship. Since we see a high F-statistic, and its corresponding p-value is very low, we can say that there is some relationship between `LifeExp` and `TotExp`
- $R^2$: The $R^2$ is positive and around 25%, which indicates that the linear model is showing some correlation, but it does not well explain the data. This intuitively makes sense given the scatterplot we observed before.
- p-value: We do see a statistical significance to the correlation between the two variables; even though the model explains a small amount of the variance, it likely a real relationship.

*Discuss whether regression assumptions are met.*

The data clearly that the relationship is not linear in the data's current state. We also are unlikely to see homoscedasticity (normally distributed residuals) were we to plot them given the shape of the data.

*Discuss implications for health policy.*

We can confirm that there is a positive relationship between increasing life expectancy and increased expenditures, however our model is not robust enough to accurately estimate expenditure costs. We will need to improve the model with some data preprocesing.

## Question 2: Transforming Variables for a Better Fit

```{r q2_transformation}
# Transform variables: LifeExp^4.6 and TotExp^0.06
who_2 <- who |> 
  mutate(TotExp = TotExp^0.06) |> 
  mutate(LifeExp = LifeExp^4.6)
```

```{r q2_visualization}
# Create a scatterplot with the transformed variables
ggplot(who_2, aes(TotExp, LifeExp)) +
  geom_point()
```

```{r q2_linear_regression}
# Run regression with transformed variables
who_model_2 <- lm(LifeExp ~ TotExp, data=who_2)
summary(who_model_2)
```

*Compare models and discuss which provides better fit.*

We can see that after our transformations, our linear model is a far better fit for the data. For one metric, our $R^2$ value has increased from 25% to 73%!

*Discuss impact of transformations on interpretation.*

By transforming our data, we've been able to keep our simple linear regression model, as well as drastically improve its performance. For such a simple transformation, this is well worth it, although we should remember to invert the operation when communicating our prediction targets.

## Question 3: Forecasting Life Expectancy Based on Transformed Expenditures

```{r q3_forecasting}
# Forecast life expectancy for specified transformed values

X_test <- tibble(TotExp = c(1.5, 2.5))
y_test <- predict(who_model_2, X_test)
y_test <- y_test ^ (1/4.6)
print(y_test)

```

*Discuss implications of these forecasts.*

With this improvement to our model, we are now in a much better position to inform the WHO predicted life expectancy at different budgets. It seems additional funding has the most impact after the age of 50, up to a plateau of 80.

## Question 4: Interaction Effects in Multiple Regression

```{r q4_multiple_regression}
# Build multiple regression model with interaction
who_model_3 <- lm(LifeExp ~ PropMD + TotExp + (PropMD*TotExp), who_2)
summary(who_model_3)
```

*Interpret F-statistic, R-squared value, standard error, and p-values.*

These additional features slightly improve our $R^2$ metric by approximately 2%

*Evaluate the interaction term.*

The interaction term describes explained variance in the presence of both `PropMD` and `TotExp`, *without regard for the variance they explain individually*. In some cases, the sum of two features is greater than the whole; this is what the interaction effect describes.

In this case, we see no statistical significance in the interaction effect between the proportion of medical doctors and total healthcare expenses, so we should not include this in our model.

*Discuss policy recommendations.*

By itself, however, `PropMD` does have a positive relationship with `LifeExp` and has improved our $R^2$, so we should keep it in the model. 

Regarding policy, we can advise the WHO that more doctors can have a positive effect on average life expectancy.

## Question 5: Forecasting Life Expectancy with Interaction Terms

```{r q5_forecasting}
# Forecast life expectancy using the multiple regression model
X_test <- tibble(TotExp = c(14), PropMD = c(0.03)) # Not transformed
y_test <- predict(who_model_3, X_test)
y_test <- y_test ^ (1/4.6)
print(y_test)
```

*Discuss whether the forecast seems realistic and limitations of the model.*

Since `TotEXP = 14` is a parameter far beyond our data (and likely an unrealistic expenditure amount to begin with), we must interpret the results with caution. Extrapolated inputs, that is data that is orders of magnitude beyond our training set, is unlikely to be accurately predicted by a simple linear model.

# Problem 3: Retail Company Analysis

## Question 1: Inventory Cost

### Scenario
A retail company is planning its inventory strategy for the upcoming year. They expect to sell 110 units of a high-demand product. The storage cost is $3.75 per unit per year, and there is a fixed ordering cost of $8.25 per order.

$$
C(Q) = \frac{D}{Q} \times S + \frac{Q}{2} \times H
$$

### Task

```{r}
# Symbolic approach

# Must initialize values for R to work with them symolically
# Values don't matter
d <- 110
s <- 8.25
h <- 3.75

fq <- expression((d / q) * s + (q / 2) * h)
fq_deriv <- D(fq, "q")
print(fq_deriv)

```

$$
f(x)` =\frac{1}{2} * 3.75 - \frac{100}{q^2} * 8.25 = 1.875 - \frac{875}{q^2}
$$
$$
1.875 - \frac{875}{q^2} = 0 \rightarrow \sqrt{q^2} = \sqrt{\frac{875}{1.875}} \rightarrow q = 21.6
$$

```{r inventory_optimization}
# Calculate optimal lot size and number of orders

# Our cost function
inventory_cost <- function(d=110, s=8.25, h=3.75, q) {
  y <- (d / q) * s + (q / 2) * h
return(y)
}

# Set up a number of potential orders
q_vec <- seq(0,100, by=1)

# Set up mock data
inventory_data <- tibble(
  x = q_vec,
  y = inventory_cost(q=q_vec)
)

# Get minimum value
ideal_order <- inventory_data |> 
  slice_min(y, n=1) |> 
  pull(x)

# Plot to help visualize the function
ggplot(inventory_data, aes(x=x, y=y)) +
  geom_histogram(stat='identity') +
  geom_hline(yintercept = min(inventory_data$y), color='red') +
  geom_vline(xintercept = (ideal_order), color='red') +
  annotate("text", x=ideal_order + 10, y = 200, label=glue("Ideal Order: {ideal_order}"))

print(ideal_order)

```

## Question 2: Revenue Maximization

### Scenario
A company is running an online advertising campaign with revenue function:
$$R(t) = -3150t^{-4} - 220t + 6530$$

### Task

```{r}
# Symbolic
# Must initialize values for R to work with them symbolically
# Values don't matter
t <- 1

fr <- expression(-3150*(t^-4) - 220*t + 6530)
fr_deriv <- D(fr, "t")
print(fr_deriv)


```
$$
R'(t) = 3150 * (t^{-(5)} * 4) - 220
$$
$$
0 = 3150 * 4t^{-(5)} - 220 \rightarrow t = 2.47
$$


```{r revenue_maximization}
# Find time at which revenue is maximized

advert_revenue <- function(t)  {
  y <- -3150*(t^-4) - 220*t + 6530
return(y)
}

t_vec <- seq(0, 50, by=1)

# Set up mock data
revenue_data <- tibble(
  x = t_vec,
  y = advert_revenue(t=t_vec)
)

# Get minimum value
ideal_campaign_length <- revenue_data |> 
  slice_max(y, n=1) |> 
  pull(x)

# Plot to help visualize the function
ggplot(revenue_data, aes(x=x, y=y)) +
  geom_histogram(stat='identity') +
  geom_hline(yintercept = max(revenue_data$y), color='red') +
  geom_vline(xintercept = (ideal_campaign_length), color='red') +
  annotate("text", x=15, y = 5000, label=glue("Ideal Duration: {ideal_campaign_length}"))

```

## Question 3: Demand Area Under Curve

### Scenario
A company sells a product with demand function:
$$P(q) = 30 - 2q$$

### Task

TODO need to take the integral

$\int^5_2(30-2q)dx$

```{r demand_curve}
# Calculate area under the demand curve

x1 <- 2
x2 <- 5

demand_func <- function(x) {
  
  y<- 2*x - 9.3
  return(y)
}

px1 <- demand_func(x1)
px2 <- demand_func(x2)

revenue_data <- tibble(
  x = c(x1, x2),
  y = c(px1, px2)
)

print(revenue_data)

ggplot(revenue_data, aes(x=x, y=y)) +
  geom_line()

integrate(demand_func, lower=-6, upper = 6)

```

## Question 4: Profit Optimization

### Scenario
A beauty supply store sells flat irons with profit function:
$$P(x) = -x^2 + 50x - 100$$

### Task
```{r profit_optimization}
# Find value of x that maximizes profit

x <- 1

px <- expression(-x^2 + 50*x -100)
px_deriv <- D(px, "x")
print(px_deriv)

```

$$
50 - 2x = 0 \rightarrow x = 25
$$

## Question 5: Spending Behavior

### Scenario
A market research firm is analyzing spending behavior with probability density function:
$$f(x) = \frac{3}{x^4}, \text{ for } x \geq 1$$

### Task
```{r spending_behavior}
# Determine if valid PDF and calculate probability

# Check if integral = 1

```

## Question 6: Market Share Estimation

### Scenario
An electronics company has market penetration rate:
$$\frac{dS}{dt} = 0.4(1-S)$$

### Task
```{r market_share}
# Integrate to find cumulative market share
```

# Problem 4: Business Optimization

## Scenario
As a data scientist at a consultancy firm, you are tasked with optimizing various business functions using Taylor Series expansions.

## Question 1: Revenue and Cost

### Scenario
A company's revenue is approximated by $R(x) = x^2e^{-0.1x}$ and cost by $C(x) = \sqrt{x^3 + 1}$.

### Task
```{r revenue_cost_taylor}
# Approximate Revenue Function using Taylor Series
# Approximate Cost Function using Taylor Series
# Compare optimization results
```

## Question 2: Financial Modeling

### Scenario
A financial analyst is modeling risk as $R(x) = \sqrt{x}$.

### Task
```{r financial_modeling}
# Derive Taylor Series expansion
# Compare approximated risk with actual function
```

## Question 3: Inventory Management

### Scenario
In a manufacturing process, demand decreases as price increases: $D(p) = 1000e^{-0.01p}$, with cost $C(p) = p^{-1}$.

### Task
```{r inventory_management}
# Expand cost function using Taylor Series
# Approximate profit function
# Suggest pricing strategy
```

## Question 4: Economic Forecasting

### Scenario
Economic growth is modeled by $G(x) = \ln(1+x)$.

### Task
```{r economic_forecasting}
# Derive Maclaurin Series expansion
# Approximate growth for small investments
# Recommend investment level
```

# Problem 5: Profit, Cost, & Pricing

## Question 1: Profit Maximization

### Scenario
A company produces two products with profit function:
$$P(x,y) = 3x^2 + 4xy - 2y^2 - 6x + 5$$

### Task
```{r profit_maxima}
# Find local maxima, minima, and saddle points
```

## Question 2: Pricing Strategy

### Scenario
A supermarket sells two competing brands with demand functions:
$$D_X(p_X, p_Y) = 15 - 2p_X + p_Y$$
$$D_Y(p_X, p_Y) = 10 + p_X - 2p_Y$$

### Task
```{r pricing_strategy}
# Find revenue function
# Determine optimal prices
```

## Question 3: Cost Minimization

### Scenario
A manufacturing company operates two plants with total cost:
$$C(x,y) = 2x^2 + 2xy + y^2 - 8x - 10y + 25$$

### Task
```{r cost_minimization}
# Determine optimal production at each plant
```

## Question 4: Marketing Mix

### Scenario
A company's marketing effectiveness is modeled by:
$$E(x,y) = 500 \ln(x+1) + 800 \ln(y+1) - 10x^2 - 20y^2$$

### Task
```{r marketing_mix}
# Find optimal spending levels
# Identify saddle points
```